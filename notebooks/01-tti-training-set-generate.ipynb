{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f7083fe511133daffeb49be461125359fe7d6b3c2688ba4e67215bcacd5aa8a4",
   "display_name": "Python 3.7.7 64-bit ('CI': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Generating training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../TTI/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "We need to first import the graph of categories."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading topics graph\n"
     ]
    }
   ],
   "source": [
    "from TTI.CategoriesGraph import CategoriesGraph\n",
    "\n",
    "graph = CategoriesGraph()\n",
    "categories = graph.categories\n"
   ]
  },
  {
   "source": [
    "For every category we need to find `s` words in the neighbourshood nodes. Let's how it works with the example category \"Machine learning algorithms\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Currently visiting: Machine learning algorithms\nCurrently visiting: Algorithms\nCurrently visiting: Machine learning\nCurrently visiting: Applied mathematics\nCurrently visiting: Computer algebra\nCurrently visiting: Algorithm description languages\nCurrently visiting: Algorithmic trading\nCurrently visiting: Approximation algorithms\nCurrently visiting: Behavior selection algorithms\nCurrently visiting: Bioinformatics algorithms\nCurrently visiting: Calendar algorithms\nCurrently visiting: Checksum algorithms\nCurrently visiting: Combinatorial algorithms\nCurrently visiting: Compression algorithms\nCurrently visiting: Computer arithmetic algorithms\nCurrently visiting: Concurrent algorithms\nCurrently visiting: Cryptographic algorithms\nCurrently visiting: Data mining algorithms\nCurrently visiting: Database algorithms\nCurrently visiting: Digit-by-digit algorithms\nCurrently visiting: Digital signal processing\nCurrently visiting: Distributed algorithms\nCurrently visiting: Error detection and correction\nCurrently visiting: Evolutionary algorithms\nCurrently visiting: External memory algorithms\nCurrently visiting: Fair division protocols\nCurrently visiting: Fingerprinting algorithms\nCurrently visiting: Graph algorithms\nCurrently visiting: Computational group theory\nCurrently visiting: Heuristic algorithms\nCurrently visiting: Line clipping algorithms\nCurrently visiting: Matrix multiplication algorithms\n"
     ]
    }
   ],
   "source": [
    "from TTI.TrainingSet import getNodeWordSet\n",
    "\n",
    "s = 50\n",
    "wordRepresentation = getNodeWordSet(\"Category:Machine learning algorithms\", graph, numberOfWords=s, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 50 words:\n\n ['protocols', 'checksum', 'correction', 'detection', 'mathematics', 'digit-by-digit', 'behavior', 'error', 'algorithmic', 'languages', 'algorithm', 'distributed', 'compression', 'algorithms', 'arithmetic', 'calendar', 'database', 'trading', 'memory', 'approximation', 'line', 'learning', 'computer', 'group', 'machine', 'heuristic', 'signal', 'mining', 'clipping', 'data', 'bioinformatics', 'processing', 'fair', 'external', 'cryptographic', 'fingerprinting', 'concurrent', 'selection', 'digital', 'and', 'division', 'graph', 'combinatorial', 'applied', 'algebra', 'theory', 'computational', 'evolutionary', 'matrix', 'description']\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {} words:\\n\\n\".format(len(wordRepresentation)), wordRepresentation)"
   ]
  },
  {
   "source": [
    "Now we can use our `doc2vec` model to encode our set of words as a numeric vector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoded numeric vector:\n [0.0016128408024087548, 0.0012727836146950722, -0.00127948890440166, -0.0005845176056027412, 0.00039609483792446554, 0.0007828212110325694, -0.0015695153269916773, -7.784669287502766e-05, -0.0011489606695249677, 0.001644849544391036, -0.0002112247166223824, 9.578494791639969e-05, 0.00015863182488828897, -0.0003390329657122493, 0.0012290972517803311, -0.0005746546667069197, -0.0009036296396516263, -0.000894396158400923, -0.0015278817154467106, 0.00039894101792015135, 0.0013593629701063037, -9.400719136465341e-05, 0.0008738027536310256, -0.0002559769491199404, -0.001644417061470449, 0.00034331606002524495, -0.0003985276853200048, 0.0016410311218351126, -0.0011706610675901175, 0.0010936153121292591, 0.0007323250756599009, -0.00130962033290416, -0.0007056671311147511, 0.00013713809312321246, -0.0015067275380715728, 0.0002579405263531953, -0.0011069539468735456, -0.00037781655555590987, 0.0016524329548701644, 0.00048557616537436843, 0.0001989162847166881, 0.0014030366437509656, -0.0006517564179375768, -0.0012203120859339833, -0.00033855382935144007, -0.0012031596852466464, 0.0015752437757328153, -2.1001855202484876e-05, 0.0012545592617243528, -0.0009258507052436471, 0.0005868382868357003, 0.00125712004955858, -0.0016000946052372456, -0.0007961929077282548, 0.0003648424462880939, -0.00014328277029562742, 0.001025251462124288, -0.00031277889502234757, 0.0011304570361971855, 0.0007286993786692619, -0.0016504344530403614, 1.3559279068431351e-05, 0.0009305289131589234, 0.0002263024653075263, -0.0005906957085244358, 0.0006519859889522195, -0.00026105085271410644, -0.000982829020358622, 0.0015258393250405788, 0.00014945892326068133, 0.0010691445786505938, 0.0012496554991230369, 0.0013481983914971352, 0.0004214768414385617, -0.00040465305210091174, 0.0011881511891260743, -0.00013915260205976665, 0.0004629440081771463, 0.0013550459407269955, 3.855609611491673e-05, -0.00014255517453420907, -0.001298377406783402, -0.0007176026701927185, 0.0009723055991344154, 0.0005690931575372815, -0.0009844762971624732, -0.0012079639127478004, 0.0011142818257212639, 0.0005578476120717824, -0.0009795821970328689, -0.0008337247418239713, 0.0011909693712368608, 0.0015786364674568176, 0.00128515949472785, -0.00047515734331682324, 0.0015049462672322989, 0.00048325813258998096, 0.0008759670308791101, 0.001453317585401237, -0.0005232319235801697, -0.0008208302315324545, 0.000589962990488857, -0.00029311588150449097, -4.977446224074811e-05, 0.001163932029157877, 0.0009112564730457962, -0.0007667585741728544, 0.0014619494322687387, 0.001082127564586699, -0.0008271537371911108, 0.00037404606700874865, -3.5759996535489336e-05, 0.001224006526172161, 0.0007401748443953693, -0.0011323719518259168, 0.0005906716687604785, -0.0010736448457464576, -0.0006343750283122063, -0.0008071038173511624, 0.0002442335244268179, 0.0013616705546155572, 0.0013259282568469644, 0.0013473654398694634, -0.001018665498122573, -0.0009569101384840906, 0.00013465018128044903, -0.0003031691303476691, 0.001129870768636465, -0.0008216490969061852, -0.0008291048579849303, -0.0004236115200910717, -0.00015452680236194283, 0.0014750271802768111, 0.0004605893336702138, 0.0006542629562318325, -0.0001335609267698601, 0.00032904770341701806, 0.0012989109382033348, 0.0011903151171281934, 0.0015181404305621982, 0.0008014152990654111, 0.0013171941973268986, -0.001449755160138011, 0.0016386616043746471, -0.0008748151012696326, 0.0007822096231393516, -0.00039243645733222365, -0.0009850842179730535, -0.0001990328310057521, -0.0014729384565725923, 3.352571002324112e-05, -0.00032674818066880107, -0.0005786528927274048, 0.00027933670207858086, -0.0004970867303200066, -0.0013106759870424867, -0.00013574949116446078, -0.0014330942649394274, 0.0007417405140586197, -0.0006066885543987155, 0.00023480445088353008, 0.0009204719099216163, -0.0012017032131552696, -0.0010844717035070062, 0.0005084079457446933, 0.0004643952415790409, 0.0013127177953720093, 0.0015657215844839811, -0.0015035823453217745, -0.00011586170876398683, 0.00041831890121102333, -0.0003600636264309287, 0.0005775466561317444, -0.0005782134830951691, 8.181919838534668e-05, 0.0011787809198722243, 0.00017954237409867346, -0.0012002967996522784, -0.0010183454724028707, 0.00031159038189798594, 0.000569158757571131, -5.461034379550256e-05, 0.0009434438543394208, 0.00011537352838786319, 0.00022365689801517874, 0.00029254096443764865, -0.0014054354978725314, 0.0007704212912358344, 0.0008019071538001299, -0.0010590851306915283, 9.663512173574418e-05, 0.0010244832374155521, -0.0003939882735721767, -0.00021574586571659893, -0.0008298956090584397, -0.0004306719347368926, -0.0004400349862407893, -9.907400817610323e-05, 0.00040487406658940017, -0.0013589487643912435, -0.00029039554647170007, 0.001560569740831852, 0.0005653828848153353, -0.0008497590897604823, -0.0014506380539387465, -0.0014977536629885435, -0.0007818157901056111, 0.000132423680042848, 0.00018951915262732655, 0.0012618954060599208, -0.001644686097279191, -0.0007001113262958825, -0.0007759782602079213, -0.0007092593587003648, -0.0006883274181745946, -2.852356556104496e-05, 0.0009659299976192415, 0.0005227248184382915, -0.001363463350571692, 0.0015637403121218085, -0.0016045838128775358, -0.001400376670062542, 0.0007853556890040636, -0.0007376366411335766, 0.0005551499198190868, 0.00010554873733781278, -0.00012638268526643515, -0.0016190912574529648, -0.0009919949807226658, -0.0002462425618432462, -0.0006368536851368845, 0.001464499393478036, -0.001204906147904694, 0.0016118499916046858, -0.0016204273561015725, -0.00032923248363658786, -0.0008799861534498632, 0.00046517112059518695, -0.0003365029115229845, 0.0015652332222089171, 9.555363794788718e-05, -0.0009776243241503835, 0.0014403676614165306, 0.0016280591953545809, 0.0010574297048151493, -0.001189215574413538, 0.001593516324646771, 0.001311051077209413, 0.0015963847981765866, -0.001478500314988196, 0.0005891891778446734, 0.001277846866287291, -0.0013540639774873853, 0.001505543477833271, 0.00014479237142950296, -0.001651893020607531, 0.00014822027878835797, 0.0003997212916146964, 4.700670251622796e-05, 0.0003400553250685334, -4.8526690079597756e-05, 0.0005257572047412395, 0.0009626664686948061, -8.19562774267979e-05, -0.0007402269402518868, 0.0005149669595994055, 0.0001348554651485756, -0.0009900315199047327, 0.0014737275196239352, -0.0009104565833695233, -0.00010289840429322794, 0.0013450013939291239, -0.0008721976773813367, 0.0013189157471060753, 0.0006314252968877554, -0.0016538983909413218, -0.0007662921561859548, -0.0011253420962020755, 0.00015319077647291124, -0.0007952055311761796, 0.0005004896665923297, 0.0007146422285586596, 6.513857078971341e-05, -0.0006569731049239635, 0.0007557710050605237, -0.0013148949947208166, -0.001431019394658506, -0.0010656489757820964, 0.0012961500324308872, 0.000294262747047469, 0.0014010777231305838, -0.0004190227191429585, 0.0008436454809270799, -0.0011598457349464297, -0.0014889384619891644, 0.00033142397296614945, -0.0012065331684425473, 0.0003462017048150301, 0.0004206821322441101, 0.0014410157455131412]\n"
     ]
    }
   ],
   "source": [
    "from TTI.doc2vec import encode_article \n",
    "\n",
    "print(\"Encoded numeric vector:\\n\", encode_article(\"\".join(wordRepresentation)))"
   ]
  },
  {
   "source": [
    "Now for every class in categories graph I need to calculate the words represntation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 100.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = []\n",
    "wordsCount = 50\n",
    "\n",
    "for category in tqdm.tqdm(categories[:10]):\n",
    "    nodeId = \"Category:{}\".format(category)\n",
    "    wordRepresentation = getNodeWordSet(nodeId, graph, numberOfWords=wordsCount)\n",
    "    numericVector = encode_article(\"\".join(wordRepresentation))\n",
    "\n",
    "    data.append([str(nodeId), json.dumps(wordRepresentation), json.dumps(numericVector)])\n",
    "\n",
    "dataFrame = pd.DataFrame(data, columns=['Category', 'Words', 'Representation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [\"subfields\", \"philosophy\", \"entertainment\", \"...   \n",
       "1  [\"subfields\", \"philosophy\", \"entertainment\", \"...   \n",
       "2  [\"subfields\", \"communication\", \"art\", \"develop...   \n",
       "3  [\"subfields\", \"philosophy\", \"sociology\", \"fore...   \n",
       "4  [\"subfields\", \"anthropologists\", \"philosophy\",...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [0.0015765804564580321, 0.0009858924895524979,...  \n",
       "1  [0.0015765804564580321, 0.0009858924895524979,...  \n",
       "2  [0.0005224531632848084, -0.001038121059536934,...  \n",
       "3  [-0.0007273228256963193, -0.001215422526001930...  \n",
       "4  [5.3492618462769315e-05, 9.856982796918601e-05...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[\"subfields\", \"philosophy\", \"entertainment\", \"...</td>\n      <td>[0.0015765804564580321, 0.0009858924895524979,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[\"subfields\", \"philosophy\", \"entertainment\", \"...</td>\n      <td>[0.0015765804564580321, 0.0009858924895524979,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[\"subfields\", \"communication\", \"art\", \"develop...</td>\n      <td>[0.0005224531632848084, -0.001038121059536934,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[\"subfields\", \"philosophy\", \"sociology\", \"fore...</td>\n      <td>[-0.0007273228256963193, -0.001215422526001930...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[\"subfields\", \"anthropologists\", \"philosophy\",...</td>\n      <td>[5.3492618462769315e-05, 9.856982796918601e-05...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "source": [
    "We won't use csv for it cause it would be to big and slow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TTI.config import DATA_DIR\n",
    "# import os\n",
    "\n",
    "# fileName= \"training_set_{}.csv\".format(wordsCount)\n",
    "# filePath = os.path.join(DATA_DIR, fileName)\n",
    "\n",
    "# dataFrame.to_csv(filePath,index_label=\"id\")"
   ]
  },
  {
   "source": [
    "## Saving dataset in the database\n",
    "\n",
    "Because caluclated dataset is huge (1.3GB) the `csv` file won't be convenient. I will use SQL database insetead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTI.config import DATABASE_PATH\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "connection = sqlite3.connect(DATABASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"training_set_{}\".format(wordsCount)\n",
    "\n",
    "dataFrame.to_sql(table_name, connection, if_exists='replace', index=False)"
   ]
  },
  {
   "source": [
    "## Testing import data from database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " importedDataFrame = pd.read_sql('select * from {}'.format(table_name), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [\"knowledge\", \"history\", \"education\", \"article...   \n",
       "1  [\"knowledge\", \"history\", \"education\", \"article...   \n",
       "2  [\"history\", \"communication\", \"professional\", \"...   \n",
       "3  [\"of\", \"engineering\", \"psychiatric\", \"history\"...   \n",
       "4  [\"of\", \"engineers\", \"geographers\", \"gun\", \"eur...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [0.0015570593532174826, 0.00048521943972446024...  \n",
       "1  [0.0015570593532174826, 0.00048521943972446024...  \n",
       "2  [0.0013619071105495095, 0.0009967258665710688,...  \n",
       "3  [-0.000537737796548754, 0.0015615752199664712,...  \n",
       "4  [-0.00039383742841891944, -0.00025646726135164...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[\"knowledge\", \"history\", \"education\", \"article...</td>\n      <td>[0.0015570593532174826, 0.00048521943972446024...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[\"knowledge\", \"history\", \"education\", \"article...</td>\n      <td>[0.0015570593532174826, 0.00048521943972446024...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[\"history\", \"communication\", \"professional\", \"...</td>\n      <td>[0.0013619071105495095, 0.0009967258665710688,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[\"of\", \"engineering\", \"psychiatric\", \"history\"...</td>\n      <td>[-0.000537737796548754, 0.0015615752199664712,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[\"of\", \"engineers\", \"geographers\", \"gun\", \"eur...</td>\n      <td>[-0.00039383742841891944, -0.00025646726135164...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "importedDataFrame.head()"
   ]
  },
  {
   "source": [
    "## Importing already created dataset from csv to database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5e098ee4f166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"training_set_{}.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordsCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Importing csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataFrameFromCsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "from TTI.config import DATA_DIR\n",
    "import os\n",
    "\n",
    "fileName= \"training_set_{}.csv\".format(wordsCount)\n",
    "filePath = os.path.join(DATA_DIR, fileName)\n",
    "\n",
    "# Importing csv\n",
    "dataFrameFromCsv = pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}