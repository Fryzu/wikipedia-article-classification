{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f7083fe511133daffeb49be461125359fe7d6b3c2688ba4e67215bcacd5aa8a4",
   "display_name": "Python 3.7.7 64-bit ('CI': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Generating training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../TTI/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "We need to first import the graph of categories."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading topics graph\n"
     ]
    }
   ],
   "source": [
    "from TTI.CategoriesGraph import CategoriesGraph\n",
    "\n",
    "graph = CategoriesGraph()\n",
    "categories = graph.categories\n"
   ]
  },
  {
   "source": [
    "For every category we need to find `s` words in the neighbourshood nodes. Let's how it works with the example category \"Machine learning algorithms\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Currently visiting: Machine learning algorithms\nCurrently visiting: Algorithms\nCurrently visiting: Machine learning\nCurrently visiting: Applied mathematics\nCurrently visiting: Computer algebra\nCurrently visiting: Algorithm description languages\nCurrently visiting: Algorithmic trading\nCurrently visiting: Approximation algorithms\nCurrently visiting: Behavior selection algorithms\nCurrently visiting: Bioinformatics algorithms\nCurrently visiting: Calendar algorithms\nCurrently visiting: Checksum algorithms\nCurrently visiting: Combinatorial algorithms\nCurrently visiting: Compression algorithms\nCurrently visiting: Computer arithmetic algorithms\nCurrently visiting: Concurrent algorithms\nCurrently visiting: Cryptographic algorithms\nCurrently visiting: Data mining algorithms\nCurrently visiting: Database algorithms\nCurrently visiting: Digit-by-digit algorithms\nCurrently visiting: Digital signal processing\nCurrently visiting: Distributed algorithms\nCurrently visiting: Error detection and correction\nCurrently visiting: Evolutionary algorithms\nCurrently visiting: External memory algorithms\nCurrently visiting: Fair division protocols\nCurrently visiting: Fingerprinting algorithms\nCurrently visiting: Graph algorithms\nCurrently visiting: Computational group theory\nCurrently visiting: Heuristic algorithms\nCurrently visiting: Line clipping algorithms\nCurrently visiting: Matrix multiplication algorithms\n"
     ]
    }
   ],
   "source": [
    "from TTI.TrainingSet import getNodeWordSet\n",
    "\n",
    "s = 50\n",
    "wordRepresentation = getNodeWordSet(\"Category:Machine learning algorithms\", graph, numberOfWords=s, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 50 words:\n\n ['algorithmic', 'combinatorial', 'digit-by-digit', 'external', 'error', 'fingerprinting', 'machine', 'mathematics', 'algebra', 'compression', 'algorithm', 'heuristic', 'and', 'mining', 'database', 'languages', 'distributed', 'processing', 'algorithms', 'protocols', 'group', 'line', 'clipping', 'division', 'signal', 'behavior', 'bioinformatics', 'checksum', 'arithmetic', 'computational', 'applied', 'evolutionary', 'graph', 'detection', 'description', 'digital', 'selection', 'theory', 'approximation', 'calendar', 'concurrent', 'memory', 'correction', 'cryptographic', 'learning', 'data', 'computer', 'trading', 'matrix', 'fair']\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {} words:\\n\\n\".format(len(wordRepresentation)), wordRepresentation)"
   ]
  },
  {
   "source": [
    "Now we can use our `doc2vec` model to encode our set of words as a numeric vector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoded numeric vector:\n [ 1.57011941e-03 -1.14319194e-03 -7.50709849e-04  3.70273629e-04\n  1.54556090e-03  9.03662702e-04  1.00285048e-03  6.65366126e-04\n  8.41695233e-04  1.15689379e-03  6.29762653e-04 -4.24629543e-04\n -4.20738739e-04  7.59956311e-04  1.28291699e-03  1.15829415e-03\n -2.90239841e-04 -6.72268390e-04 -8.38602195e-04 -1.22561643e-03\n  1.48316589e-03 -1.57441816e-03 -1.21585195e-04  9.09041672e-04\n  4.52965993e-04 -2.93156863e-05  1.32239284e-03  7.16225943e-04\n -9.27706715e-04  4.09226282e-04  4.44408885e-04  1.57303584e-03\n -8.31634330e-04  1.45097321e-03 -1.18715968e-03 -1.62772811e-03\n  8.43850896e-04  1.20600371e-03  1.46042637e-03 -1.53379852e-03\n -1.65229791e-03  4.15280694e-04  4.11874731e-04 -6.86984451e-04\n  9.05374472e-04 -1.36414135e-04 -9.55812517e-04  1.26046571e-03\n -1.05738733e-03  1.52708008e-03 -1.42025715e-03 -1.04907656e-03\n  1.44765759e-03 -4.93587984e-04  1.44493370e-03  3.91225767e-04\n -1.04183084e-04 -1.43711281e-03 -5.27591270e-04 -1.31794158e-03\n  1.25375029e-03  1.24152936e-03  7.82029878e-04  1.09769544e-03\n  1.21656235e-03 -3.40347615e-04  9.50836984e-04  1.80528834e-04\n -1.59820227e-03  1.55166583e-03 -4.01990430e-04 -4.91770334e-04\n -1.31725438e-03 -6.34468859e-04  1.18325453e-03 -1.43844029e-03\n  1.60612992e-03 -1.53751846e-03 -1.12191762e-03  1.22734369e-03\n  1.38559204e-03  8.27086507e-04 -3.37291858e-05  9.79930395e-04\n -1.55031565e-03 -1.32858159e-03 -9.77518153e-04  4.71205509e-04\n  1.01225975e-04 -3.71456932e-04 -9.49695241e-05 -1.38342229e-03\n  5.82912064e-04 -4.55440691e-04 -7.54844630e-04  2.10727332e-04\n  5.35315776e-05  9.93111520e-04 -1.58650789e-03 -4.51122847e-04\n -1.31100765e-03  1.43064640e-03 -9.22072853e-04  5.99711086e-04\n -6.80397148e-04 -3.75151023e-04  1.10310060e-03  3.43295862e-04\n -1.36541890e-03  2.83916976e-04  1.37632224e-03  7.48276361e-04\n  6.00631931e-04  8.19403067e-06  1.58654724e-03 -3.10591655e-04\n  8.73265439e-04 -6.50447211e-04 -1.64144521e-03 -1.06874376e-03\n -2.52729427e-04 -6.00741303e-04  9.12811665e-04  1.05140987e-03\n  8.44962837e-04  1.62349408e-03  1.32427411e-03  1.19719189e-03\n  1.35622697e-03 -1.56340224e-03  5.00282273e-04  1.03173434e-05\n  1.16964697e-03  4.06370018e-05 -1.00798975e-03 -1.62381527e-03\n -7.69020233e-04 -1.28529593e-03 -1.22553832e-03  1.34344702e-03\n -8.11834238e-04  1.22096133e-03 -1.40039469e-04  1.29284139e-03\n  4.25545586e-04 -1.04996003e-03 -1.27884815e-03 -1.56333810e-03\n -1.25022046e-03 -3.41908890e-04  1.60208810e-03 -1.28433312e-04\n  4.27076651e-04 -8.25973402e-04 -1.30133051e-03 -1.01642281e-05\n  1.44426955e-03 -7.60762312e-04  1.26144141e-05 -6.38003461e-04\n  9.06286645e-04  1.09780964e-03  1.51970156e-03  1.27973489e-03\n  2.52822996e-04  1.10153947e-03 -6.79826422e-04 -6.15387224e-04\n  2.15193111e-04 -3.52926931e-04  8.08154175e-04 -8.21973023e-04\n -1.14262417e-04  7.00892124e-04 -1.36237463e-03 -1.08915428e-03\n -5.80918684e-04 -1.11215829e-03 -1.13647955e-03  4.15264309e-04\n  1.47904595e-03 -1.54972088e-03 -4.17389820e-04  6.36906596e-04\n -1.06845913e-03 -1.29234651e-03 -1.04584103e-03  8.66858580e-04\n -1.61678460e-03 -9.41575621e-04 -1.13703916e-03 -1.56903709e-03\n  6.77711621e-04  1.38091797e-03 -5.76307822e-04  1.26902293e-03\n  7.75234948e-04  7.68679078e-04  1.47783814e-03  1.16338825e-03\n  1.13490003e-03 -9.37654986e-04  2.42730530e-04  1.64767960e-03\n -1.95281245e-04  3.15040321e-04  7.83715106e-04 -5.76871564e-04\n -7.55336252e-04 -4.09372558e-04  8.21617607e-04  9.50296177e-04\n -1.16006273e-03  9.78032127e-04 -1.13947864e-03  1.44850637e-03\n  1.10811507e-03 -1.03989954e-03 -1.47443428e-03 -1.15980592e-03\n  1.59460015e-03 -9.93522932e-04  1.49652315e-03 -2.10485159e-04\n -1.41757668e-03  3.66033404e-04 -6.12973061e-04  1.55462569e-03\n -6.70525915e-05 -4.04584600e-04  1.44535137e-04  5.91222604e-04\n  9.27658286e-04  7.73631269e-04  5.21602378e-05 -1.35775330e-03\n  5.59643202e-04 -1.65374367e-03  5.26012329e-04  1.63446076e-03\n -1.29596493e-03 -1.21625746e-03 -5.61198394e-04  1.75264562e-04\n -1.42332527e-03  4.84122342e-04 -8.35004961e-04  1.63689523e-03\n  3.87594948e-04  4.85566670e-05  1.49232137e-03 -1.25572248e-03\n -5.42399182e-04  1.16978737e-03  1.55251124e-03 -1.47174625e-03\n  1.06658284e-04  1.49013079e-03 -5.93742123e-04  6.58472243e-04\n -9.16346500e-04 -1.63692178e-03  1.18488667e-03  1.70650274e-05\n  8.36555613e-04 -1.52092733e-04 -3.78460973e-04 -1.14153030e-04\n  6.45358174e-04 -1.27700134e-03 -1.61711080e-03  2.92679499e-04\n  6.59428129e-04  3.74585972e-04  1.31170300e-03 -3.23416083e-04\n  1.14350312e-03 -8.02356866e-04  2.65874551e-04 -4.94778738e-04\n  1.37903763e-03  1.39644707e-03 -1.15552929e-03 -9.39387712e-04\n -2.52513448e-04  1.64863816e-03  1.65294984e-03 -8.81605491e-04\n  1.39169150e-03  1.22237427e-03  9.81516903e-04 -1.32151600e-03\n -3.16551130e-04 -2.91344331e-04 -3.83715203e-04 -3.81189020e-04\n -1.58795388e-03 -3.73545481e-04 -1.41454930e-03 -1.40409346e-03]\n"
     ]
    }
   ],
   "source": [
    "from TTI.doc2vec import encode_article \n",
    "\n",
    "print(\"Encoded numeric vector:\\n\", encode_article(\"\".join(wordRepresentation)))"
   ]
  },
  {
   "source": [
    "Now for every class in categories graph I need to calculate the words represntation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 109.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "wordsCount = 50\n",
    "\n",
    "for category in tqdm.tqdm(categories):\n",
    "    nodeId = \"Category:{}\".format(category)\n",
    "    wordRepresentation = getNodeWordSet(nodeId, graph, numberOfWords=wordsCount)\n",
    "    numericVector = encode_article(\"\".join(wordRepresentation))\n",
    "    data.append([nodeId, wordRepresentation, numericVector])\n",
    "\n",
    "dataFrame = pd.DataFrame(data, columns=['Category', 'Words', 'Representation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [subfields, main, mathematics, main_topic_clas...   \n",
       "1  [subfields, main, mathematics, main_topic_clas...   \n",
       "2  [subfields, main, arts, academics, biblical, m...   \n",
       "3  [archaeological, meteorology, subfields, seism...   \n",
       "4  [subfields, violence, archaeologists, bioinorg...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [7.1092065e-05, 0.0015041557, 0.0012917432, 0....  \n",
       "1  [7.1092065e-05, 0.0015041557, 0.0012917432, 0....  \n",
       "2  [0.0011213522, -3.3170538e-05, 0.0010152729, 0...  \n",
       "3  [-0.0016465506, -0.0006757527, 0.0015840229, 0...  \n",
       "4  [-0.0007645557, -0.0009938681, 0.0014720332, -...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[subfields, main, mathematics, main_topic_clas...</td>\n      <td>[7.1092065e-05, 0.0015041557, 0.0012917432, 0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[subfields, main, mathematics, main_topic_clas...</td>\n      <td>[7.1092065e-05, 0.0015041557, 0.0012917432, 0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[subfields, main, arts, academics, biblical, m...</td>\n      <td>[0.0011213522, -3.3170538e-05, 0.0010152729, 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[archaeological, meteorology, subfields, seism...</td>\n      <td>[-0.0016465506, -0.0006757527, 0.0015840229, 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[subfields, violence, archaeologists, bioinorg...</td>\n      <td>[-0.0007645557, -0.0009938681, 0.0014720332, -...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTI.config import DATA_DIR\n",
    "import os\n",
    "\n",
    "fileName= \"training_set_{}.csv\".format(wordsCount)\n",
    "filePath = os.path.join(DATA_DIR, fileName)\n",
    "\n",
    "dataFrame.to_csv(filePath,index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}