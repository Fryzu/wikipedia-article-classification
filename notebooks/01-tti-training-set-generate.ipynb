{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f7083fe511133daffeb49be461125359fe7d6b3c2688ba4e67215bcacd5aa8a4",
   "display_name": "Python 3.7.7 64-bit ('CI': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Generating training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../TTI/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "We need to first import the graph of categories."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading topics graph\n"
     ]
    }
   ],
   "source": [
    "from TTI.CategoriesGraph import CategoriesGraph\n",
    "\n",
    "graph = CategoriesGraph()\n",
    "categories = graph.categories\n"
   ]
  },
  {
   "source": [
    "For every category we need to find `s` words in the neighbourshood nodes. Let's how it works with the example category \"Machine learning algorithms\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Currently visiting: Machine learning algorithms\nCurrently visiting: Algorithms\nCurrently visiting: Machine learning\nCurrently visiting: Applied mathematics\nCurrently visiting: Computer algebra\nCurrently visiting: Algorithm description languages\nCurrently visiting: Algorithmic trading\nCurrently visiting: Approximation algorithms\nCurrently visiting: Behavior selection algorithms\nCurrently visiting: Bioinformatics algorithms\nCurrently visiting: Calendar algorithms\nCurrently visiting: Checksum algorithms\nCurrently visiting: Combinatorial algorithms\nCurrently visiting: Compression algorithms\nCurrently visiting: Computer arithmetic algorithms\nCurrently visiting: Concurrent algorithms\nCurrently visiting: Cryptographic algorithms\nCurrently visiting: Data mining algorithms\nCurrently visiting: Database algorithms\nCurrently visiting: Digit-by-digit algorithms\nCurrently visiting: Digital signal processing\nCurrently visiting: Distributed algorithms\nCurrently visiting: Error detection and correction\nCurrently visiting: Evolutionary algorithms\nCurrently visiting: External memory algorithms\nCurrently visiting: Fair division protocols\nCurrently visiting: Fingerprinting algorithms\nCurrently visiting: Graph algorithms\nCurrently visiting: Computational group theory\nCurrently visiting: Heuristic algorithms\nCurrently visiting: Line clipping algorithms\nCurrently visiting: Matrix multiplication algorithms\n"
     ]
    }
   ],
   "source": [
    "from TTI.TrainingSet import getNodeWordSet\n",
    "\n",
    "s = 50\n",
    "wordRepresentation = getNodeWordSet(\"Category:Machine learning algorithms\", graph, numberOfWords=s, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 50 words:\n\n ['digit-by-digit', 'fingerprinting', 'distributed', 'compression', 'database', 'theory', 'calendar', 'processing', 'fair', 'detection', 'description', 'division', 'cryptographic', 'evolutionary', 'computer', 'behavior', 'bioinformatics', 'selection', 'matrix', 'heuristic', 'algorithms', 'algebra', 'memory', 'correction', 'mathematics', 'languages', 'trading', 'arithmetic', 'clipping', 'applied', 'algorithmic', 'approximation', 'combinatorial', 'concurrent', 'data', 'external', 'mining', 'line', 'and', 'computational', 'machine', 'graph', 'learning', 'algorithm', 'group', 'digital', 'signal', 'error', 'protocols', 'checksum']\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {} words:\\n\\n\".format(len(wordRepresentation)), wordRepresentation)"
   ]
  },
  {
   "source": [
    "Now we can use our `doc2vec` model to encode our set of words as a numeric vector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoded numeric vector:\n [0.000769761682022363, 0.00104153947904706, 0.001104172901250422, -0.0010914006270468235, 0.001523416256532073, -0.0008398314821533859, -0.0002713746507652104, -0.00016400939784944057, 0.0007764255278743804, 0.001134060206823051, -9.191171557176858e-05, -0.0011730362894013524, -0.0009643429075367749, 0.0011036876821890473, 0.00034393538953736424, -0.001230453490279615, 0.0005936514353379607, -0.0013741335133090615, -0.00028574577299878, 0.0012393228244036436, 0.0011314357398077846, -0.0014283099444583058, -0.0011511000338941813, -0.0007595731876790524, -0.0004886173992417753, -0.000738111964892596, -0.00018758358783088624, 0.0010885816300287843, 0.0016476402524858713, -0.00030863904976285994, 0.00033458275720477104, -0.0007464617374353111, 0.0009380666306242347, -0.00035741293686442077, -0.0013418991584330797, -0.00034419193980284035, 0.0006167967221699655, -0.0010554930195212364, -0.0007203014101833105, 0.000428474391810596, 0.0013010621769353747, 0.0015696437330916524, -0.0007423119968734682, -0.00013649245374836028, -0.001341169117949903, -0.001592852408066392, 0.0012948570074513555, 0.0012639987980946898, 0.0011345737148076296, 0.0014184105675667524, 0.0008404009277001023, -0.0004089754947926849, 0.0014922292903065681, -0.0013334379764273763, 0.0009202348301187158, 0.0006397797842510045, -0.0016553173772990704, -0.00047131162136793137, -0.0013959851348772645, 0.00159700948279351, 0.0003258239012211561, -0.0008820231887511909, -0.00034270287142135203, 6.65977131575346e-05, -0.0011781435459852219, 0.0009424177114851773, -0.0003606187819968909, -0.001537682837806642, 0.0003739076491910964, -0.0008100347477011383, 0.0008636092534288764, 0.0008806564146652818, -0.0003943175252061337, 0.0003197902115061879, -0.0006353810313157737, -0.0016174293123185635, 0.000286412046989426, -0.0014242557808756828, 0.0005601136945188046, -5.327007966116071e-05, 0.0006950506358407438, 0.0014861986273899674, 0.00107281852979213, -0.0013805635971948504, -0.0006666211411356926, -0.00035647035110741854, -0.0013723897282034159, -0.0010254500666633248, -0.0006932221003808081, -0.0008422337123192847, 0.0007721071015112102, 5.6031934946076944e-05, -0.00037164115929044783, -0.0009591482812538743, -0.0015995053108781576, 2.12830382224638e-05, -0.0004362193576525897, 0.0009979608003050089, -0.0011723946081474423, 0.00033824981073848903, -4.188047387287952e-05, 0.001655637752264738, -0.0001071147489710711, -0.0013374855043366551, -0.0010131904855370522, 0.0009075042908079922, -0.0007340946467593312, 0.0004890909185633063, 1.5757301298435777e-05, 0.0013415857683867216, -0.0014003599062561989, 0.0015264912508428097, 0.0013949335552752018, 0.0004632040217984468, 0.0009895986877381802, 0.001276921364478767, 0.0012685356196016073, 0.0005173777462914586, -0.0005358431953936815, 0.0016323721501976252, 0.00046046750503592193, 0.001106110867112875, 0.0009168681572191417, 0.000717304355930537, 0.000866558460984379, -0.0007588250446133316, -0.00014441450184676796, -0.0010726641630753875, 0.001045270822942257, 0.001338583999313414, 0.0013740818249061704, -0.001534580602310598, 0.0004825829528272152, 0.0014804366510361433, 2.3728342057438567e-05, -0.0011982013238593936, 0.0004907303955405951, 0.00013229243631940335, 0.0012886006152257323, -0.0012375396909192204, 0.0003168389084748924, 0.001290884567424655, 0.00022437334700953215, 0.0012640230124816298, -0.0016137020429596305, -0.0012609956320375204, -0.0005069349426776171, -0.0011686941143125296, 0.0006113845156505704, -0.0010807353537529707, 0.0010884864022955298, -0.00044056103797629476, 0.0005786289111711085, -0.0003782558487728238, 0.0001571552420500666, 0.0008903957204893231, -0.0013590868329629302, -0.001518620876595378, -0.00020297667651902884, 0.00015565317880827934, -0.0009760155808180571, 0.0015919560100883245, 0.001184233115054667, 0.0015153636923059821, -0.0001859800104284659, -0.0004414524300955236, 0.0005364497192203999, 0.0003912512038368732, 0.0011265674838796258, -0.0005640351446345448, 0.0011962107382714748, 0.0015504559269174933, 0.0006454510730691254, 0.0012310867896303535, -0.0010519104544073343, -0.0008317052852362394, 0.0006838034023530781, -0.0016483076615259051, -0.0004720313008874655, -0.0014770097332075238, 7.027104584267363e-05, 0.0009492957033216953, 0.0008489802130497992, -0.00022674279171042144, 0.0006391171482391655, 0.0010510374559089541, 0.0014797679614275694, -0.0010745925828814507, -0.0014655627310276031, -0.000608022150117904, 0.00037198091740719974, -6.121864259966969e-08, -0.00024649465922266245, 0.0008615240803919733, -0.0010825232602655888, 0.00034759630216285586, -0.0006783788558095694, -0.0004691706853918731, 0.001226525055244565, -0.0011782185174524784, 0.0015247116098180413, -0.00043129047844558954, 0.0005773229640908539, 3.951997496187687e-05, -0.0011621330631896853, -0.0005688450182788074, -0.0012546161888167262, 0.0013734402600675821, -0.0008567097247578204, -0.0006907769129611552, 0.0008057508384808898, 0.000262551853666082, -0.000956531148403883, 0.0013174685882404447, -0.0013402254553511739, -9.912981477100402e-05, 0.0013284360757097602, 0.0009437667904421687, -0.001092299586161971, 0.0005167964263819158, -2.1544979063037317e-06, -0.0012502948520705104, -8.457070362055674e-05, 0.000826252275146544, 0.0008744635269977152, 0.0014332231367006898, -0.0012116404250264168, 0.0001396396110067144, -0.001521918224170804, 0.0006495762499980628, -8.454501221422106e-05, -0.0006892530946061015, 0.00018400473345536739, 0.0007499305065721273, 0.0012400683481246233, -0.0009360628318972886, 0.00023715186398476362, 0.0004090958973392844, 0.0012719782534986734, -0.0014069535536691546, 0.0005766942631453276, -6.665560067631304e-05, 0.0014566349564120173, 0.0003864919999614358, 0.0009946507634595037, 0.0012959260493516922, 0.0007519123028032482, -0.0006820057169534266, -0.00028316667885519564, -0.0006875446997582912, -2.0699057131423615e-05, -0.0003832587681245059, 0.0003082725452259183, 0.0014019054360687733, 0.0005535080563277006, -0.0010287159821018577, -0.0007722518057562411, 0.001608157646842301, -0.0005097449175082147, -0.0015425181481987238, 0.0007924613310024142, 8.424078987445682e-05, 0.0014882782706990838, 0.0002790660073515028, -0.0013801614986732602, 0.0013684678124263883, -0.001549368491396308, -0.0006819798145443201, -0.00024409515026491135, 0.0014706976944580674, 0.000786007905844599, -0.0005295333103276789, -0.0014542235294356942, 0.0005341485375538468, 0.001098979264497757, 0.0001723430905258283, -0.0006618570769205689, -0.0007864954532124102, -4.4316384446574375e-05, -0.001405832590535283, 0.00028488331008702517, 0.00023417067131958902, 8.821496885502711e-05, -0.0015905468026176095, -6.108232628321275e-05, 0.0011628128122538328, 0.0013681412674486637, 0.0005332916625775397, -0.0006359434337355196, -0.0008277151500806212, 0.0001137071376433596, -0.0014354586601257324, -0.001077920664101839, -0.001067684032022953, 0.0005824790569022298, 0.0016064762603491545, -0.0010256464593112469, -0.000362688850145787, -0.0010589550947770476, -6.20922219241038e-05]\n"
     ]
    }
   ],
   "source": [
    "from TTI.doc2vec import encode_article \n",
    "\n",
    "print(\"Encoded numeric vector:\\n\", encode_article(\"\".join(wordRepresentation)))"
   ]
  },
  {
   "source": [
    "Now for every class in categories graph I need to calculate the words represntation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 225765/225765 [49:18<00:00, 76.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = []\n",
    "wordsCount = 50\n",
    "\n",
    "for category in tqdm.tqdm(categories):\n",
    "    nodeId = \"Category:{}\".format(category)\n",
    "    wordRepresentation = getNodeWordSet(nodeId, graph, numberOfWords=wordsCount)\n",
    "    numericVector = encode_article(\"\".join(wordRepresentation))\n",
    "\n",
    "    data.append([str(nodeId), json.dumps(wordRepresentation), json.dumps(numericVector)])\n",
    "\n",
    "dataFrame = pd.DataFrame(data, columns=['Category', 'Words', 'Representation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [\"world\", \"articles\", \"music\", \"technology\", \"...   \n",
       "1  [\"world\", \"articles\", \"music\", \"technology\", \"...   \n",
       "2  [\"communication\", \"articles\", \"subject\", \"scie...   \n",
       "3  [\"areas\", \"fields\", \"information\", \"subject\", ...   \n",
       "4  [\"gun\", \"anthropologists\", \"cartographers\", \"s...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [9.195921302307397e-05, -0.0007309274515137076...  \n",
       "1  [9.195921302307397e-05, -0.0007309274515137076...  \n",
       "2  [-0.0007150950841605663, 0.0004406595544423908...  \n",
       "3  [0.001037890324369073, 0.00026856939075514674,...  \n",
       "4  [0.0008707719971425831, 0.0003855710383504629,...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[\"world\", \"articles\", \"music\", \"technology\", \"...</td>\n      <td>[9.195921302307397e-05, -0.0007309274515137076...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[\"world\", \"articles\", \"music\", \"technology\", \"...</td>\n      <td>[9.195921302307397e-05, -0.0007309274515137076...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[\"communication\", \"articles\", \"subject\", \"scie...</td>\n      <td>[-0.0007150950841605663, 0.0004406595544423908...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[\"areas\", \"fields\", \"information\", \"subject\", ...</td>\n      <td>[0.001037890324369073, 0.00026856939075514674,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[\"gun\", \"anthropologists\", \"cartographers\", \"s...</td>\n      <td>[0.0008707719971425831, 0.0003855710383504629,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "source": [
    "We won't use csv for it cause it would be to big and slow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TTI.config import DATA_DIR\n",
    "# import os\n",
    "\n",
    "# fileName= \"training_set_{}.csv\".format(wordsCount)\n",
    "# filePath = os.path.join(DATA_DIR, fileName)\n",
    "\n",
    "# dataFrame.to_csv(filePath,index_label=\"id\")"
   ]
  },
  {
   "source": [
    "## Saving dataset in the database\n",
    "\n",
    "Because caluclated dataset is huge (1.3GB) the `csv` file won't be convenient. I will use SQL database insetead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTI.config import DATABASE_PATH\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "connection = sqlite3.connect(DATABASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"training_set_{}\".format(wordsCount)\n",
    "\n",
    "dataFrame.to_sql(table_name, connection, if_exists='replace', index=False)"
   ]
  },
  {
   "source": [
    "## Testing import data from database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " importedDataFrame = pd.read_sql('select * from {}'.format(table_name), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [\"knowledge\", \"history\", \"education\", \"article...   \n",
       "1  [\"knowledge\", \"history\", \"education\", \"article...   \n",
       "2  [\"history\", \"communication\", \"professional\", \"...   \n",
       "3  [\"of\", \"engineering\", \"psychiatric\", \"history\"...   \n",
       "4  [\"of\", \"engineers\", \"geographers\", \"gun\", \"eur...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [0.0015570593532174826, 0.00048521943972446024...  \n",
       "1  [0.0015570593532174826, 0.00048521943972446024...  \n",
       "2  [0.0013619071105495095, 0.0009967258665710688,...  \n",
       "3  [-0.000537737796548754, 0.0015615752199664712,...  \n",
       "4  [-0.00039383742841891944, -0.00025646726135164...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[\"knowledge\", \"history\", \"education\", \"article...</td>\n      <td>[0.0015570593532174826, 0.00048521943972446024...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[\"knowledge\", \"history\", \"education\", \"article...</td>\n      <td>[0.0015570593532174826, 0.00048521943972446024...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[\"history\", \"communication\", \"professional\", \"...</td>\n      <td>[0.0013619071105495095, 0.0009967258665710688,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[\"of\", \"engineering\", \"psychiatric\", \"history\"...</td>\n      <td>[-0.000537737796548754, 0.0015615752199664712,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[\"of\", \"engineers\", \"geographers\", \"gun\", \"eur...</td>\n      <td>[-0.00039383742841891944, -0.00025646726135164...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "importedDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}