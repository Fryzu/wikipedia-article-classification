{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f7083fe511133daffeb49be461125359fe7d6b3c2688ba4e67215bcacd5aa8a4",
   "display_name": "Python 3.7.7 64-bit ('CI': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Generating training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../TTI/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "We need to first import the graph of categories."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading topics graph\n"
     ]
    }
   ],
   "source": [
    "from TTI.CategoriesGraph import CategoriesGraph\n",
    "\n",
    "graph = CategoriesGraph()\n",
    "categories = graph.categories\n"
   ]
  },
  {
   "source": [
    "For every category we need to find `s` words in the neighbourshood nodes. Let's how it works with the example category \"Machine learning algorithms\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Currently visiting: Machine learning algorithms\nCurrently visiting: Algorithms\nCurrently visiting: Machine learning\nCurrently visiting: Applied mathematics\nCurrently visiting: Computer algebra\nCurrently visiting: Algorithm description languages\nCurrently visiting: Algorithmic trading\nCurrently visiting: Approximation algorithms\nCurrently visiting: Behavior selection algorithms\nCurrently visiting: Bioinformatics algorithms\nCurrently visiting: Calendar algorithms\nCurrently visiting: Checksum algorithms\nCurrently visiting: Combinatorial algorithms\nCurrently visiting: Compression algorithms\nCurrently visiting: Computer arithmetic algorithms\nCurrently visiting: Concurrent algorithms\nCurrently visiting: Cryptographic algorithms\nCurrently visiting: Data mining algorithms\n"
     ]
    }
   ],
   "source": [
    "from TTI.TrainingSet import getNodeWordSet\n",
    "\n",
    "s = 25\n",
    "wordRepresentation = getNodeWordSet(\"Category:Machine learning algorithms\", graph, numberOfWords=s, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 25 words:\n\n ['checksum', 'algorithmic', 'trading', 'compression', 'calendar', 'concurrent', 'learning', 'approximation', 'bioinformatics', 'algorithms', 'mining', 'computer', 'algebra', 'behavior', 'machine', 'languages', 'algorithm', 'mathematics', 'combinatorial', 'selection', 'description', 'applied', 'cryptographic', 'arithmetic', 'data']\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {} words:\\n\\n\".format(len(wordRepresentation)), wordRepresentation)"
   ]
  },
  {
   "source": [
    "Now we can use our `doc2vec` model to encode our set of words as a numeric vector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoded numeric vector:\n [0.2933642864227295, 0.2660072445869446, -0.9961421489715576, 0.32041075825691223, 0.3270479142665863, 0.12687724828720093, 0.44342032074928284, -0.09991951286792755, 0.14271588623523712, 0.40499868988990784, -0.5897689461708069, -0.812658965587616, -0.5341119766235352, 0.07815662026405334, -0.15428920090198517, -0.22551512718200684, -0.1138901337981224, 0.20030979812145233, -0.28977683186531067, 0.5738781690597534, -0.5722239017486572, -0.3731054961681366, 0.11635565757751465, -0.6711048483848572, 0.05266357958316803, 0.1287587434053421, -0.010078768245875835, -0.2355613112449646, -0.3634723722934723, -0.6536797881126404, -0.6671356558799744, 0.3736737072467804, 0.1605260670185089, -0.2588902711868286, -0.63358473777771, 0.03217832371592522, 0.4962356686592102, -0.15260177850723267, 0.0866607055068016, -0.35474470257759094, -0.013663590885698795, -0.04957647621631622, -0.6806261539459229, -0.31088557839393616, -0.22451043128967285, 0.2916729152202606, 0.06963380426168442, -0.22547516226768494, 0.33368241786956787, -0.09995362162590027, 0.1223483681678772, 0.4946955144405365, -0.49273252487182617, 0.03241409361362457, -0.3273429274559021, 0.520723819732666, 0.18374870717525482, 0.3745688498020172, -0.06396878510713577, 0.16343411803245544, -0.4070822596549988, -0.44573885202407837, 0.23839309811592102, 0.2636743187904358, -0.16448864340782166, 0.432985782623291, -0.15478765964508057, -0.3188698887825012, 0.23051664233207703, -0.30696967244148254, 0.04978815093636513, -0.6237080097198486, 0.6872442364692688, 0.5495485663414001, 0.015025547705590725, -0.2102939635515213, -0.10169021040201187, 0.47850164771080017, -0.4249114990234375, -0.39569738507270813, 0.41105952858924866, -0.5863410830497742, 0.07688066363334656, 1.0381261110305786, -0.4307835102081299, 0.04442479461431503, 0.26258212327957153, -0.1487581729888916, 0.03300630301237106, 0.43344175815582275, -0.015970202162861824, -0.5461733937263489, 0.2538436949253082, -0.06393856555223465, -0.5792823433876038, 0.47178003191947937, 0.9137406945228577, -0.04259912297129631, 0.32815372943878174, -0.46170276403427124, 0.44408363103866577, 0.09509120136499405, -0.36286357045173645, -0.3023712635040283, 0.7053868770599365, -0.5234553217887878, 0.15065549314022064, 0.24625709652900696, 0.6748579144477844, -0.2431056946516037, -0.2538101375102997, 0.07522501051425934, 0.3144274652004242, -0.13244979083538055, -0.4010465443134308, -0.3129879832267761, -0.23978003859519958, -0.021960830315947533, 0.16057921946048737, -0.061624567955732346, -0.8496116995811462, 0.07641619443893433, -0.07447429746389389, -0.33164843916893005, -0.11058788746595383, -0.19309405982494354, 0.22361257672309875, -0.7002025246620178, -0.45335015654563904, 0.24803994596004486, -0.3587673306465149, 0.38019073009490967, 0.1324276626110077, -0.7235830426216125, 0.1679632067680359, 0.38662758469581604, -0.3253955543041229, 0.09849552065134048, 0.04507598653435707, 0.3310133218765259, 0.2518776059150696, -0.49604520201683044, -0.04868251830339432, 0.6445218920707703, 0.3458470404148102, 0.23279818892478943, -0.021738125011324883, -0.3454791307449341, 0.7854633927345276, -0.10263023525476456, -0.5172737836837769, -0.3178170919418335, -0.47948935627937317, -0.6644361019134521, -0.36730965971946716, -0.20582690834999084, 0.3110097050666809, -0.42962971329689026, 0.11113462597131729, 0.2886691987514496, 0.4068549871444702, 0.7919303178787231, 0.004082198720425367, 0.5486430525779724, 0.06295974552631378, 0.028757745400071144, -0.3755510151386261, 0.26333025097846985, 0.2994616627693176, 0.058762334287166595, -0.1434418261051178, -0.000579862215090543, 0.29055020213127136, 0.27124375104904175, 0.8584055304527283, -0.5197438597679138, 0.10930994153022766, 0.3140311539173126, -0.40474751591682434, -0.1199740618467331, 0.4509779214859009, 0.4208422303199768, -0.7358541488647461, -0.41917791962623596, 0.705023467540741, -0.257310152053833, -0.033414967358112335, 0.5692022442817688, -0.1584581732749939, 0.08525942265987396, 0.446420282125473, 0.05658470839262009, -0.08569034188985825, 0.3485981225967407, -0.09003376960754395, -0.5708434581756592, 1.1888381242752075, -1.2739322185516357, -0.49465644359588623, -0.5568819046020508, -0.020260313525795937, -0.6783236861228943, 0.8296173214912415, -0.14262916147708893, -0.2941533327102661, -0.0019759931601583958, -0.7972618937492371, -0.43913009762763977, 0.1927899867296219, -0.6181121468544006, 0.37668853998184204, 0.06560617685317993, 0.13275712728500366, 0.2894303500652313, 0.18971718847751617, -0.7951362133026123, 0.2570093274116516, -0.2524474263191223, -0.40077099204063416, -0.42494016885757446, 0.5436312556266785, 0.10095273703336716, -0.215346559882164, 0.10160587728023529, -0.15450598299503326, -0.021252987906336784, -0.439299076795578, 0.12624682486057281, 0.2673260271549225, -0.07632952183485031, -0.260530024766922, 0.13251961767673492, 0.616645336151123, 0.05978532135486603, 0.7998903393745422, 0.4932633936405182, -0.025191551074385643, -0.5179541110992432, 0.3949309289455414, -0.46786049008369446, -1.008039116859436, 0.4791785180568695, -0.07908748835325241, 0.5698498487472534, 0.2732919752597809, -0.7711144685745239, -0.028897996991872787, 0.21525311470031738, -0.33142784237861633, 0.3899039328098297, 0.03796125948429108, 0.3039902150630951, 0.41296061873435974, 0.22486698627471924, -0.919916570186615, 0.24922221899032593, 0.4253632128238678, -0.11220914125442505, 0.03686731681227684, -0.35568082332611084, 0.004465967882424593, -0.21635118126869202, -0.7990083694458008, -0.11326069384813309, -0.25870367884635925, -0.004173642490059137, -0.058537986129522324, 0.038065355271101, -0.6097779273986816, 0.04391653463244438, 0.29860052466392517, 0.5793941617012024, 0.023276440799236298, 0.3172769546508789, -0.5008757710456848, -0.37506240606307983, -0.24234095215797424, -0.5112759470939636, 0.20982691645622253, -0.11236102879047394, 0.35538747906684875, 0.4300682246685028, -0.49654191732406616, 0.4241769313812256, 1.1610937118530273, 0.043030768632888794, 0.13474644720554352, 0.30181148648262024, -0.4869614243507385, -0.4107258915901184, -0.23062250018119812, -0.06180322542786598, -0.290938138961792, -0.29225975275039673, -0.5772597193717957, -0.3308749198913574, -0.4503640830516815, 0.14977124333381653, -0.3164685070514679, 0.07177215069532394]\n"
     ]
    }
   ],
   "source": [
    "from TTI.doc2vec import encode_article \n",
    "\n",
    "article = \" \".join(wordRepresentation)\n",
    "\n",
    "print(\"Encoded numeric vector:\\n\", encode_article(article))"
   ]
  },
  {
   "source": [
    "Now for every class in categories graph I need to calculate the words represntation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1000/225765 [01:34<5:53:02, 10.61it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9c09ee22bca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnodeId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Category:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwordRepresentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNodeWordSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodeId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfWords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwordsCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnumericVector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordRepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodeId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordRepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studia/3-taksonomia-identyfikacja-tekstu/TTI/TTI/doc2vec.py\u001b[0m in \u001b[0;36mencode_article\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mformatted_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     vector_representation = doc2vec.infer_vector(\n\u001b[0;32m---> 14\u001b[0;31m         formatted_content, alpha=start_alpha, steps=infer_epoch)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvector_representation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/CI/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36minfer_vector\u001b[0;34m(self, doc_words, alpha, min_alpha, epochs, steps)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 train_document_dbow(\n\u001b[1;32m    679\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoctag_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                     \u001b[0mlearn_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoctag_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoctag_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoctag_locks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoctag_locks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m                 )\n\u001b[1;32m    682\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdm_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = []\n",
    "wordsCount = 25\n",
    "\n",
    "for category in tqdm.tqdm(categories):\n",
    "    nodeId = \"Category:{}\".format(category)\n",
    "    wordRepresentation = getNodeWordSet(nodeId, graph, numberOfWords=wordsCount)\n",
    "    numericVector = encode_article(\" \".join(wordRepresentation))\n",
    "\n",
    "    data.append([str(nodeId), json.dumps(wordRepresentation), json.dumps(numericVector)])\n",
    "\n",
    "dataFrame = pd.DataFrame(data, columns=['Category', 'Words', 'Representation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [\"world\", \"articles\", \"music\", \"technology\", \"...   \n",
       "1  [\"world\", \"articles\", \"music\", \"technology\", \"...   \n",
       "2  [\"communication\", \"articles\", \"subject\", \"scie...   \n",
       "3  [\"areas\", \"fields\", \"information\", \"subject\", ...   \n",
       "4  [\"gun\", \"anthropologists\", \"cartographers\", \"s...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [9.195921302307397e-05, -0.0007309274515137076...  \n",
       "1  [9.195921302307397e-05, -0.0007309274515137076...  \n",
       "2  [-0.0007150950841605663, 0.0004406595544423908...  \n",
       "3  [0.001037890324369073, 0.00026856939075514674,...  \n",
       "4  [0.0008707719971425831, 0.0003855710383504629,...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[\"world\", \"articles\", \"music\", \"technology\", \"...</td>\n      <td>[9.195921302307397e-05, -0.0007309274515137076...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[\"world\", \"articles\", \"music\", \"technology\", \"...</td>\n      <td>[9.195921302307397e-05, -0.0007309274515137076...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[\"communication\", \"articles\", \"subject\", \"scie...</td>\n      <td>[-0.0007150950841605663, 0.0004406595544423908...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[\"areas\", \"fields\", \"information\", \"subject\", ...</td>\n      <td>[0.001037890324369073, 0.00026856939075514674,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[\"gun\", \"anthropologists\", \"cartographers\", \"s...</td>\n      <td>[0.0008707719971425831, 0.0003855710383504629,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "source": [
    "We won't use csv for it cause it would be to big and slow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TTI.config import DATA_DIR\n",
    "# import os\n",
    "\n",
    "# fileName= \"training_set_{}.csv\".format(wordsCount)\n",
    "# filePath = os.path.join(DATA_DIR, fileName)\n",
    "\n",
    "# dataFrame.to_csv(filePath,index_label=\"id\")"
   ]
  },
  {
   "source": [
    "## Saving dataset in the database\n",
    "\n",
    "Because caluclated dataset is huge (1.3GB) the `csv` file won't be convenient. I will use SQL database insetead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTI.config import DATABASE_PATH\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "connection = sqlite3.connect(DATABASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"training_set_{}\".format(wordsCount)\n",
    "\n",
    "dataFrame.to_sql(table_name, connection, if_exists='replace', index=False)"
   ]
  },
  {
   "source": [
    "## Testing import data from database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " importedDataFrame = pd.read_sql('select * from {}'.format(table_name), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    Category  \\\n",
       "0        Category:Main_topic_classifications   \n",
       "1               Category:Main topic articles   \n",
       "2              Category:Academic disciplines   \n",
       "3  Category:Subfields by academic discipline   \n",
       "4              Category:Scholars by subfield   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [\"knowledge\", \"history\", \"education\", \"article...   \n",
       "1  [\"knowledge\", \"history\", \"education\", \"article...   \n",
       "2  [\"history\", \"communication\", \"professional\", \"...   \n",
       "3  [\"of\", \"engineering\", \"psychiatric\", \"history\"...   \n",
       "4  [\"of\", \"engineers\", \"geographers\", \"gun\", \"eur...   \n",
       "\n",
       "                                      Representation  \n",
       "0  [0.0015570593532174826, 0.00048521943972446024...  \n",
       "1  [0.0015570593532174826, 0.00048521943972446024...  \n",
       "2  [0.0013619071105495095, 0.0009967258665710688,...  \n",
       "3  [-0.000537737796548754, 0.0015615752199664712,...  \n",
       "4  [-0.00039383742841891944, -0.00025646726135164...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Category:Main_topic_classifications</td>\n      <td>[\"knowledge\", \"history\", \"education\", \"article...</td>\n      <td>[0.0015570593532174826, 0.00048521943972446024...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Category:Main topic articles</td>\n      <td>[\"knowledge\", \"history\", \"education\", \"article...</td>\n      <td>[0.0015570593532174826, 0.00048521943972446024...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Category:Academic disciplines</td>\n      <td>[\"history\", \"communication\", \"professional\", \"...</td>\n      <td>[0.0013619071105495095, 0.0009967258665710688,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Category:Subfields by academic discipline</td>\n      <td>[\"of\", \"engineering\", \"psychiatric\", \"history\"...</td>\n      <td>[-0.000537737796548754, 0.0015615752199664712,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Category:Scholars by subfield</td>\n      <td>[\"of\", \"engineers\", \"geographers\", \"gun\", \"eur...</td>\n      <td>[-0.00039383742841891944, -0.00025646726135164...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "importedDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}