{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f7083fe511133daffeb49be461125359fe7d6b3c2688ba4e67215bcacd5aa8a4",
   "display_name": "Python 3.7.7 64-bit ('CI': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../TTI/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Taksonomia, identyfikacja tekstu\n",
    "\n",
    "Dany jest fragment hierarchii klasyfkacji tematycznej z Wikipedii (https://en.wikipedia.org/wiki/Category:Main_topic_classifications) w postaci pliku CSV.\n",
    "Klasyfkacja jest grafem spójnym, gdzie węzły są tematami, a krawędzie reprezentują uszczegółowienie tematu.\n",
    "\n",
    "Celem projektu jest zapropnowanie i przetestowanie mechanizmu automatycznej klasyfikacji tekstu Wejściem jest plik tekstowy w języku angielskim. Wyjściem jest zbiór węzłów w/w klasyfikacji tematycznej.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dane wejściowe\n",
    "\n",
    "Dane wejściowe do zadania do graf spójny o 225765 węzłach, kady węzeł reprezentuje jedną kategorię. Graf nie jest uporządkowanym drzewem, może również zawierać pętle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from TTI.CategoriesGraph import CategoriesGraph\n",
    "\n",
    "categories = CategoriesGraph()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading topics graph\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ilość krawędzi (339250, 2)\nIlość węzłów 225765\n"
     ]
    }
   ],
   "source": [
    "print(\"Ilość krawędzi\", categories._edge_list.shape)\n",
    "print(\"Ilość węzłów\", categories._graph.number_of_nodes())"
   ]
  },
  {
   "source": [
    "## Zbiór treningowy\n",
    "\n",
    "Zbiór treningowy został przygotowany z wykorzystaniem notebooka `01-tti-training-set-generate.ipynb`. Tam jest też więcej informacji o procesie generacji."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTI.config import DATABASE_PATH\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "table_name = \"training_set_25\"\n",
    "connection = sqlite3.connect(DATABASE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_sql('select * from {}'.format(table_name), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Representation\"] = dataset[\"Representation\"].apply(lambda i : json.loads(i))\n",
    "dataset[\"Category\"] = dataset[\"Category\"].apply(lambda i : i[9:])\n",
    "dataset[\"Words\"] = dataset[\"Words\"].apply(lambda i : json.loads(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset size: (225765, 3)\nNumeric represntation vector size: 300\nNumber of nodes in the graph: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", dataset.shape)\n",
    "print(\"Numeric represntation vector size:\", len(dataset.iloc[12][\"Representation\"]))\n",
    "print(\"Number of nodes in the graph:\", len(dataset.iloc[12][\"Words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                Category  \\\n",
       "0             Main_topic_classifications   \n",
       "1                    Main topic articles   \n",
       "2                   Academic disciplines   \n",
       "3       Subfields by academic discipline   \n",
       "4                   Scholars by subfield   \n",
       "...                                  ...   \n",
       "225760              World Wide Web stubs   \n",
       "225761        Internet publication stubs   \n",
       "225762                     Website stubs   \n",
       "225763        Wikimedia Foundation stubs   \n",
       "225764                          Universe   \n",
       "\n",
       "                                                    Words  \\\n",
       "0       [academic, culture, human, entertainment, heal...   \n",
       "1       [academic, culture, human, entertainment, heal...   \n",
       "2       [academic, art, academics, euthenics, studies,...   \n",
       "3       [subfield, academic, areas, evolutionary, fiel...   \n",
       "4       [subfield, academic, architects, studies, clas...   \n",
       "...                                                   ...   \n",
       "225760  [internet, wide, system, technology, bioinform...   \n",
       "225761  [service, wide, entertainment, online, news, s...   \n",
       "225762  [websites, service, wide, entertainment, onlin...   \n",
       "225763  [websites, service, wide, entertainment, onlin...   \n",
       "225764  [academic, matter, culture, entertainment, hea...   \n",
       "\n",
       "                                           Representation  \n",
       "0       [-0.3755445182323456, 0.010519789531826973, -0...  \n",
       "1       [-0.40671899914741516, 0.013835961930453777, -...  \n",
       "2       [-0.09239675104618073, -0.46590009331703186, -...  \n",
       "3       [0.085173599421978, 0.010392077267169952, -0.3...  \n",
       "4       [-0.15292514860630035, -0.5975006222724915, -0...  \n",
       "...                                                   ...  \n",
       "225760  [0.216136172413826, -0.024581177160143852, -0....  \n",
       "225761  [0.2748589515686035, 0.2310565859079361, -0.34...  \n",
       "225762  [0.1632257103919983, 0.16291794180870056, -0.2...  \n",
       "225763  [0.19932252168655396, 0.19686073064804077, -0....  \n",
       "225764  [-0.24487195909023285, -0.2658485770225525, -0...  \n",
       "\n",
       "[225765 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Main_topic_classifications</td>\n      <td>[academic, culture, human, entertainment, heal...</td>\n      <td>[-0.3755445182323456, 0.010519789531826973, -0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Main topic articles</td>\n      <td>[academic, culture, human, entertainment, heal...</td>\n      <td>[-0.40671899914741516, 0.013835961930453777, -...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Academic disciplines</td>\n      <td>[academic, art, academics, euthenics, studies,...</td>\n      <td>[-0.09239675104618073, -0.46590009331703186, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Subfields by academic discipline</td>\n      <td>[subfield, academic, areas, evolutionary, fiel...</td>\n      <td>[0.085173599421978, 0.010392077267169952, -0.3...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Scholars by subfield</td>\n      <td>[subfield, academic, architects, studies, clas...</td>\n      <td>[-0.15292514860630035, -0.5975006222724915, -0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>225760</th>\n      <td>World Wide Web stubs</td>\n      <td>[internet, wide, system, technology, bioinform...</td>\n      <td>[0.216136172413826, -0.024581177160143852, -0....</td>\n    </tr>\n    <tr>\n      <th>225761</th>\n      <td>Internet publication stubs</td>\n      <td>[service, wide, entertainment, online, news, s...</td>\n      <td>[0.2748589515686035, 0.2310565859079361, -0.34...</td>\n    </tr>\n    <tr>\n      <th>225762</th>\n      <td>Website stubs</td>\n      <td>[websites, service, wide, entertainment, onlin...</td>\n      <td>[0.1632257103919983, 0.16291794180870056, -0.2...</td>\n    </tr>\n    <tr>\n      <th>225763</th>\n      <td>Wikimedia Foundation stubs</td>\n      <td>[websites, service, wide, entertainment, onlin...</td>\n      <td>[0.19932252168655396, 0.19686073064804077, -0....</td>\n    </tr>\n    <tr>\n      <th>225764</th>\n      <td>Universe</td>\n      <td>[academic, matter, culture, entertainment, hea...</td>\n      <td>[-0.24487195909023285, -0.2658485770225525, -0...</td>\n    </tr>\n  </tbody>\n</table>\n<p>225765 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "source": [
    "## Wyszukiwanie najbardziej podobnych wektorów"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Do klasyfikacji posłuże się obliczaniem odległości geometrycznej pomiędzy wektorami reprezentacji doc2vec. Wektory o najmniejszej odległości zostaną zakwalifikowane jako najbardziej podobne."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         Category  \\\n",
       "2692  Machine learning algorithms   \n",
       "\n",
       "                                                  Words  \\\n",
       "2692  [checksum, algorithmic, trading, compression, ...   \n",
       "\n",
       "                                         Representation  \n",
       "2692  [0.302137166261673, 0.3030090630054474, -1.029...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Words</th>\n      <th>Representation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2692</th>\n      <td>Machine learning algorithms</td>\n      <td>[checksum, algorithmic, trading, compression, ...</td>\n      <td>[0.302137166261673, 0.3030090630054474, -1.029...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dataset.loc[dataset['Category'] == \"Machine learning algorithms\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name of category Machine learning algorithms\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "name = dataset[\"Category\"][2692]\n",
    "vector = dataset[\"Representation\"][2692]\n",
    "\n",
    "print(\"Name of category\", name)"
   ]
  },
  {
   "source": [
    "Teraz należe znaleźć najbardziej podobne kategorie. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def find_simmilar(vector, count, df):\n",
    "    \"\"\" Finds 'count' best matching categories with vectors simmilar to 'vector'\"\"\"\n",
    "    categories = []\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        vec = row[\"Representation\"]\n",
    "        name = row[\"Category\"]\n",
    "        categories.append((name, spatial.distance.cosine(vector, vec)))\n",
    "    sorted_categories = sorted(categories, key=lambda i: i[1])\n",
    "    return sorted_categories[0:count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 225765/225765 [00:40<00:00, 5637.08it/s]\n"
     ]
    }
   ],
   "source": [
    "best_matching = find_simmilar(vector, 20, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Machine learning algorithms', 0.0),\n",
       " ('Heuristic algorithms', 0.03048611901635534),\n",
       " ('Cryptographic algorithms', 0.033841232971325574),\n",
       " ('Computer arithmetic algorithms', 0.034831473629752474),\n",
       " ('Data mining algorithms', 0.03487279219354722),\n",
       " ('Compression algorithms', 0.035516547716642144),\n",
       " ('Digit-by-digit algorithms', 0.03591962687260464),\n",
       " ('Algorithms', 0.03608325172873006),\n",
       " ('Bioinformatics algorithms', 0.03669657755224942),\n",
       " ('Approximation algorithms', 0.03737963968331992),\n",
       " ('Statistical algorithms', 0.037658969638839856),\n",
       " ('Quantum algorithms', 0.037759472173684916),\n",
       " ('Graph algorithms', 0.038569196633341796),\n",
       " ('Pseudo-polynomial time algorithms', 0.039990344459672755),\n",
       " ('Routing algorithms', 0.04005739003276043),\n",
       " ('Selection algorithms', 0.04025399420522191),\n",
       " ('Algorithm description languages', 0.043534683809688834),\n",
       " ('Calendar algorithms', 0.045350172497429675),\n",
       " ('Distributed algorithms', 0.04660966816597345),\n",
       " ('Streaming algorithms', 0.04691549780262483)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "best_matching"
   ]
  },
  {
   "source": [
    "Jak widać na przykładzie powyżej dla kategorii `Machine learning algorithms` algorytm znalazł 20 najbardziej podobnych klas. Najbardziej podobna okazała się kategoria `Heuristic algroithms`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Heuristic algorithms', 0.03048611901635534)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "best_matching[1]"
   ]
  },
  {
   "source": [
    "## Klasyfikacja dokumentu tekstowego\n",
    "\n",
    "Mając już algorytm będący w stanie porównać 2 wektory reprezentacji numerycznej `doc2vec` można przejść do właściwej implementacji zadania, czyli klasyfikacji prawdziwego artykułu. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "W pierwszym kroku należy przeprowadzić ekstrakcję zbioru słów charakterystycznych dla danego dokumentu tekstowego. Słowa te zostaną następnie wykorzystane do generacji wektora numerycznej reprezentacji artykułu przy użyciu modeulu `doc2vec`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found words:  ['class', 'datum', 'example', 'point', 'classification', 'training', 'neighbor', 'algorithm', 'feature', 'distance', 'error', 'classifier', 'rate', 'set', 'prototype', 'label', 'number', 'analysis', 'reduction', 'outlier', 'regression', 'value', 'weight', 'neighbour', 'search', 'dimension', 'data', 'input', 'object', 'distribution', 'vector', 'space', 'query', 'border', 'ratio', 'test', 'problem', 'approach', 'result', 'extraction', 'method', 'accuracy', 'technique', 'step', 'map', 'density', 'boundary', 'decision', 'case', 'output', 'property', 'function', 'scale', 'x', 'sample', 'constant', 'metric', 'variable', 'way', 'representation', 'effect', 'information', 'size', 'risk', 'expansion', 'term', 'order', 'figure', 'fig', 'k', 'vote', 'average', 'type', 'computation', 'evaluation']\n"
     ]
    }
   ],
   "source": [
    "from TTI.TextDocument import get_document_representation, get_article_content\n",
    "\n",
    "# Finds Wikipedia article by name and downloads it using Wikipedia API\n",
    "article = get_article_content(\"K-nearest_neighbors_algorithm\")\n",
    "\n",
    "representation = get_document_representation(article, words_count=75) # How many od the words found in the article should when creating vector\n",
    "\n",
    "document_words = representation['words']\n",
    "document_vector = representation['vector']\n",
    "\n",
    "print(\"Found words: \", document_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numeric vector:  [-0.13973025977611542, 0.8803226351737976, -0.954968273639679, -1.4638932943344116, 0.7967787384986877, 1.2005836963653564, -0.2745325565338135, -0.22412803769111633, -1.8432432413101196, -0.6706209778785706, -0.536053478717804, 0.4469451606273651, 0.6560133695602417, -0.5908300876617432, -0.45293983817100525, -0.33585020899772644, -0.16023124754428864, -0.5544490814208984, 0.06164596974849701, 0.6012845039367676, -0.35053005814552307, 0.12409500032663345, -0.12851309776306152, 0.05405285954475403, 0.44916659593582153, -0.7805129885673523, -0.06957641243934631, 0.08045163005590439, -0.7114368677139282, -0.8525400757789612, -0.8904473781585693, 0.00835314579308033, 0.28191035985946655, 0.5773045420646667, 0.21824778616428375, 0.6881959438323975, 0.3126390874385834, -0.11073076725006104, 1.3967258930206299, -0.018726421520113945, -0.6426990032196045, 0.8602242469787598, -0.06603698432445526, 0.8466103076934814, -0.46289312839508057, 0.8824690580368042, 0.07958546280860901, 0.029247283935546875, 0.2943377196788788, 0.22134636342525482, -0.596757173538208, -0.7315691709518433, 0.8310250639915466, -0.008103778585791588, 0.23213519155979156, -0.46641603112220764, 0.17654196918010712, -0.07540403306484222, -0.690723180770874, 0.5381945967674255, -0.23663507401943207, 0.8435807228088379, 0.5665414929389954, 0.2409730851650238, 1.072228193283081, -0.25851500034332275, 0.44678738713264465, 0.4732799232006073, 1.3086845874786377, -0.04192909598350525, -0.09288407862186432, 0.08501283824443817, -0.34629762172698975, 0.20358321070671082, -0.696861207485199, -0.26687878370285034, 0.088178850710392, 0.1063317060470581, -0.30715593695640564, 0.5060441493988037, 1.473926067352295, -0.055761367082595825, 0.7305747866630554, 0.4914206266403198, -0.3381960093975067, -0.27538245916366577, 0.3379661440849304, -0.036744412034749985, -1.1794922351837158, 0.03894641250371933, -0.5040473341941833, -1.3587956428527832, -0.9057566523551941, -0.048992909491062164, -1.07099449634552, 0.6006944179534912, 0.031816516071558, -0.09983929991722107, 0.2647494673728943, 0.36608490347862244, -0.008799644187092781, -0.025004517287015915, 0.34846174716949463, -0.7119868397712708, 1.0574489831924438, -1.2318631410598755, -0.8550440669059753, -0.007849987596273422, -0.02734440565109253, -0.8583469390869141, -0.20370957255363464, -0.047717880457639694, -0.3041657507419586, -0.35252082347869873, 0.2484384924173355, -0.4487534165382385, 0.6278654932975769, -0.4917238652706146, -0.29145103693008423, 0.5466949939727783, -0.8053684234619141, -0.3155817687511444, -1.2031809091567993, -0.09367688000202179, -0.10219968855381012, 0.5777495503425598, -0.06418656557798386, 0.5887260437011719, 0.0436510406434536, 0.37434157729148865, 1.0903987884521484, 0.6449618935585022, 0.009718828834593296, -0.5789868235588074, -0.5402318239212036, -0.20495916903018951, -0.478072851896286, -1.2510970830917358, -0.37586715817451477, 1.2201288938522339, 0.4775806665420532, 0.08791954070329666, 1.2822297811508179, -0.22653575241565704, 0.4875594675540924, 0.6674164533615112, -1.0284334421157837, -0.1901593804359436, 0.7975044846534729, 0.45356568694114685, 0.10253072530031204, 0.06633825600147247, -0.19749724864959717, -0.26051169633865356, 0.28421300649642944, 0.14194178581237793, -0.6317857503890991, -1.2792936563491821, 0.16405370831489563, 0.18987391889095306, -0.09872236847877502, 0.5144043564796448, -0.3447926342487335, 0.15601715445518494, 0.08531254529953003, 0.15396802127361298, 0.14710964262485504, -0.5147314071655273, 0.5798622965812683, 0.04570569470524788, 0.607103705406189, 0.28129592537879944, 1.6607990264892578, 0.14395983517169952, 1.430647611618042, -0.9567782282829285, -1.0746632814407349, 1.198005199432373, -0.5846037268638611, 0.33426913619041443, -0.16304372251033783, 0.5257279276847839, 0.5662480592727661, -0.6218677759170532, -0.3603929877281189, -0.3379680812358856, -0.9865443110466003, 0.8150368928909302, 0.3286290168762207, -0.0932554304599762, 0.15310364961624146, -0.8284993767738342, -0.059089288115501404, 0.10497593879699707, 0.8975831270217896, -0.14487691223621368, 0.24133123457431793, -0.4819466769695282, -0.3785295784473419, -0.7748706936836243, -0.9210922718048096, -0.08873989433050156, 1.2948161363601685, 0.11155526340007782, -0.024307897314429283, 0.8632819652557373, -0.3586767017841339, 0.327518105506897, -0.5073248744010925, -0.5025840401649475, -0.8933826684951782, 0.29286426305770874, -0.7074628472328186, -0.20146752893924713, 0.08388766646385193, 0.12177219986915588, 0.678986132144928, 0.0993286520242691, 0.5633379817008972, -0.841653048992157, 0.5078738927841187, -0.042014990001916885, -1.1639769077301025, 0.356428861618042, -0.17840631306171417, -0.2300543338060379, -0.9146420955657959, -0.029601415619254112, 0.4304501712322235, 0.5589041113853455, 0.6388676762580872, 0.1709057241678238, -0.6323664784431458, -0.3352549076080322, -0.26100611686706543, 0.14380742609500885, -1.3757295608520508, -0.4977673590183258, -0.1477111279964447, 0.16998104751110077, -1.463380217552185, -0.19588959217071533, 0.31741079688072205, 1.1542140245437622, -0.04902651533484459, -1.1748448610305786, -0.058660972863435745, -0.003396360669285059, -0.01816248707473278, -0.348480224609375, -0.3833245038986206, -0.45499056577682495, -0.5375478267669678, 0.6744958758354187, -0.3146107494831085, 0.4228673279285431, 1.3985530138015747, -0.6432172656059265, 0.7715387344360352, -0.18946987390518188, -0.43469277024269104, -0.32708150148391724, 0.2566894292831421, -0.4899516999721527, 0.1315118819475174, 0.449832022190094, -0.21356600522994995, 1.0650537014007568, -0.7183661460876465, -0.3653234839439392, -0.041373930871486664, 1.0593624114990234, 1.0449851751327515, -0.2380272001028061, 0.040121812373399734, -0.6792382001876831, -0.31706729531288147, -0.39894381165504456, -0.37385687232017517, 0.7754653096199036, -0.47233229875564575, 0.2502320110797882, -1.115951418876648, 0.3430551290512085, 0.34282252192497253, -0.07186490297317505, -0.27382713556289673, -0.293745756149292, 0.24700699746608734, -0.5084300637245178, -0.7613403797149658, 0.7563132643699646, -0.6452285647392273, 0.8638893365859985, -0.9057731032371521, 0.11275412142276764, -0.7535317540168762, 0.4298169016838074, 0.5157491564750671, -0.8242174983024597]\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric vector: \", document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 225765/225765 [00:46<00:00, 4819.82it/s]\n"
     ]
    }
   ],
   "source": [
    "best_matching = find_simmilar(document_vector, 5, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Object recognition and categorization', 0.6043233070349052),\n",
       " ('Learning in computer vision', 0.6117157606695703),\n",
       " ('Air force units and formations by type', 0.6123609738092128),\n",
       " ('Internet advertising methods', 0.615647974472145),\n",
       " ('Contextual advertising', 0.6175729562705745)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "best_matching"
   ]
  },
  {
   "source": [
    "Algorytm wykrył 5 kategorii z grafu wejściowego do których najbardziej \"pasuje\" artykuł o \"K nearest neighbors algorithm\".\n",
    "\n",
    "Są to klasy:\n",
    "* Object recognition and categorization\n",
    "* Internet advertising methods\n",
    "* Contextual advertising\n",
    "* Air force units and formations by type"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Inne przykłady"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classified_categories(document_name, words_count=50, categories_count=5):\n",
    "    article = get_article_content(document_name)\n",
    "    representation = get_document_representation(article, words_count) # How many od the words found in the article should when creating vector\n",
    "\n",
    "    document_words = representation['words']\n",
    "    document_vector = representation['vector']\n",
    "    print(\"Found words: \", document_words)\n",
    "\n",
    "    best_matching = find_simmilar(document_vector, categories_count, dataset)\n",
    "    return best_matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 593/225765 [00:00<00:38, 5923.02it/s]Found words:  ['equation', 'field', 'charge', 'law', 'material', 'formulation', 'surface', 'current', 'form', 'space', 'unit', 'wave', 'time', 'vector', 'light', 'phenomenon', 'quantum', 'term', 'tensor', 'density', 'condition', 'version', 'theory', 'volume', 'spacetime', 'line', 'relation', 'scale', 'polarization', 'loop', 'definition', 'solution', 'speed', 'example', 'operator', 'curl', 'system', 'magnetization', 'force', 'change', 'consequence', 'vacuum', 'matter', 'potential', 'value', 'relativity', 'physics', 'component', 'quantity', 'divergence']\n",
      "100%|██████████| 225765/225765 [00:36<00:00, 6130.19it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Dirac equation', 0.47262195755523584),\n",
       " ('Units of electrical conductance', 0.5105260627377728),\n",
       " ('Units of electrical resistance', 0.5201984424947701),\n",
       " ('Quantum electrodynamics', 0.5211182432355765),\n",
       " ('Magnetic monopoles', 0.524841188862891)]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "get_classified_categories(\"Maxwell's equations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1019/225765 [00:00<00:43, 5156.81it/s]Found words:  ['covid-19', 'virus', 'infection', 'disease', 'people', '%', 'case', 'symptom', 'risk', 'treatment', 'protein', 'rate', 'death', 'antibody', 'age', 'study', 'surface', 'cell', 'time', 'day', 'lung', 'woman', 'syndrome', 'transmission', 'hand', 'use', 'result', 'factor', 'population', 'blood', 'response', 'mortality', 'number', 'patient', 'level', 'storm', 'effect', 'condition', 'measure', 'research', 'human', 'man', 'year', 'testing', 'mask', 'group', 'host', 'health', 'hospital', 'heart']\n",
      "100%|██████████| 225765/225765 [00:37<00:00, 5944.79it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Elder law', 0.565619938441521),\n",
       " ('Risk factors', 0.5676282560972064),\n",
       " ('Cross-sectional analysis', 0.5794792989270499),\n",
       " ('Medical law journals', 0.5802471747474864),\n",
       " ('Observational study', 0.5815167426234842)]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "get_classified_categories(\"COVID-19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 1220/225765 [00:00<00:36, 6118.12it/s]Found words:  ['learning', 'machine', 'datum', 'algorithm', 'model', 'training', 'example', 'method', 'system', 'input', 'set', 'feature', 'computer', 'task', 'network', 'field', 'rule', 'decision', 'problem', 'bias', 'classification', 'prediction', 'approach', 'analysis', 'knowledge', 'output', 'function', 'regression', 'detection', 'statistic', 'mining', 'program', 'representation', 'time', 'goal', 'environment', 'technique', 'tree', 'application', 'theory', 'performance', 'variable', 'neuron', 'people', 'intelligence', 'research', 'pattern', 'class', 'programming', 'information']\n",
      "100%|██████████| 225765/225765 [00:36<00:00, 6146.28it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Machine learning researchers', 0.4397311011007218),\n",
       " ('Logic programming researchers', 0.4412704569362673),\n",
       " ('Loss functions', 0.4591873063314801),\n",
       " ('Expert systems', 0.46839583850828126),\n",
       " ('Markov models', 0.4742454348302344)]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "get_classified_categories(\"Machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 1154/225765 [00:00<00:38, 5775.71it/s]Found words:  ['application', 'framework', 'developer', 'platform', 'version', 'datum', 'ios', 'background', 'thread', 'web', 'app', 'development', 'code', 'team', 'css', 'source', 'tv', 'macos', 'capability', 'history', 'mistake', 'company', 'experience', 'way', 'element', 'basis', 'prototype', 'order', 'technology', 'month', 'talk', 'production', 'implementation', 'principle', 'dom', 'process', 'end', 'device', 'communicate', 'bridge', 'react', 'api', 'paradigm', 'styling', 'syntax', 'message', 'view', 'language', 'example', 'program']\n",
      "100%|██████████| 225765/225765 [00:37<00:00, 6083.22it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Web frameworks', 0.5893907456203118),\n",
       " ('Ajax (programming)', 0.5933646821684826),\n",
       " ('Component-based software engineering', 0.5971404285860622),\n",
       " ('Web developers', 0.5978359344648014),\n",
       " ('Audio to video synchronization', 0.6031584457844819)]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "get_classified_categories(\"React Native\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}